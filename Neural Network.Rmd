---
title: "Neural Networks"
author: "Xinyue Tan"
date: "3/11/2019"
output: html_document
---

## Part I - Introduction to Using Neural Nets

In the attached data sets attention1.csv and attention2.csv, there is data that describe features assocaited with webcam images of 100 students' faces as they particpate in an online discussion. The variables are:

eyes - student has their eyes open (1 = yes, 0 = no)
face.forward - student is facing the camera (1 = yes, 0 = no)
chin.up - student's chin is raised above 45 degrees (1 = yes, 0 = no)
attention - whether the student was paying attention when asked (1 = yes, 0 = no)

I will use the webcam data to build a neural net to predict whether or not a student is attending.


# Install and load package
First install and load the neuralnet package
```{r}
install.packages("neuralnet")
library(neuralnet)
```

# Upload the data
```{r}
D1 <-read.csv("attention1.csv", header=TRUE)
  
D2 <-read.csv("attention2.csv", header=TRUE)
```

# Build a neural network
Now I can build a neural net that predicts attention based on webcam images. The command "neuralnet" sets up the model. It is composed of four basic arguments:

- A formula that describes the inputs and outputs of the neural net (attention is our output)
- The data frame that the model will use
- How many hidden layers are in our neural net
- A threshold that tells the model when to stop adjusting weights to find a better fit. If error does not change more than the threshold from one iteration to the next, the algorithm will stop (We will use 0.01, so if prediction error does not change by more than 1% from one iteration to the next the algorithm will halt)

```{r}
net <- neuralnet(attention ~ eyes + face.forward + chin.up, D1, hidden = 1, threshold = 0.01)
#threshold: a numeric value specifying the threshold for the partial derivatives of the error function as stopping criteria
pdf("Neural_network1.pdf")
plot(net)
dev.off()
```

I have now trained a neural network. The plot shows me the layers of my newtork as black nodes and edges with the calculated weights on each edge. The blue nodes and edges are called bias terms. The bias term anchors the activation function, the weights change the shape of the activation function while the bias term changes the overall position of the activation function - if I have used linear regression, the bias term is like the intercept of the regression equation, it shifts the trend line up and down the y axis, while the other parameters change the angle of the line. The plot also reports the final error rate and the number of iterations ("steps") that it took to reach these weights.

# Build a second neural network
Increase the number of hidden layers in the neural net and build a second neural net with more layers in it.  Determine if this improves the predictions or not.

# Use preferred neural network to predict
Now use your preferred neural net to predict the second data set. 

```{r}
net2<-neuralnet(attention ~eyes +face.forward +chin.up,D1, hidden=3, threshold = 0.01)
pdf("Neural_network2.pdf")
plot(net2)
dev.off()
#As I increase the number of hidden layers, the error decreases which means that the pridiction become more precise. The new model improves the prediction. When the number of steps is bigger, it has higher probaility of overfitting.
#Definition of error: defines the error between the desired output and the calculated output of the neural network on input for a set of input-output pairs

library(dplyr)

# Create a new data frame (D3) that only includes the input layers to use this command.
D3 <-select(D1, eyes, face.forward, chin.up)

```

Create predictions using your neural net
```{r}
net.prediction <- neuralnet::compute(net2, D3)
#You can access the predictions from your model as "net.prediction$net.result". Predictions will be numeric estimates from 1 or 0, convert these into exact predictions of 1 and 0 and then determine the accuracy of your neural net on this new data.

D1$prediction<-net.prediction$net.result
D1$prediction<-ifelse(D1$prediction>=0.5, 1, 0)
table(D1$attention, D1$prediction) 

#on new data
net.prediction2<-neuralnet::compute(net2, D2)
D2$prediction<-net.prediction2$ net.result
D2$prediction<-ifelse(D2$prediction> 0.5,1,0)
table(D2$attention, D2$prediction)

```

## Analysis and Conclusion:

1. How accurate is the neural net? How can you tell?
   * The accuracty on the train sample is 100%. 6/100=6%, the accuracy level of the test sample is 94% 

2. What does the model explain? 
   * This model is predicting if students are playing attention based on three basic phisiological characteristics (if student has their eyes open, if student is facing the camera, if the student's chin is raised above 45 degrees). The prediction model assigns weights to each of these characteristics and used those to predict the outcome which is whether the student is playing attention. The accuracy of the model is 94%.

3. Real facial recognition is very complex though. Would a neural network be a good solution for predicting real facial movements? Why, why not? 
   * There are so many variables of facial movements involved (e.g.: not only eyes, face.forward and chin.up), and detecting those variables increases the difficulty to use the neural network to predict real facial recognition difficult. 
   * As long as we can segment facial movemnts into tiny distinct elements and define each element accurately, this algorithm can add value to education industry. It can not only detect which student is not paying attention, but also react correspondently to help the student increase learning outcomes.






